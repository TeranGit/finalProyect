{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO DE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha utilizado RandomForestClassifier como modelo de machine learning. Esta elección se basa en la flexibilidad y buen rendimiento de los bosques aleatorios en problemas de clasificación.\n",
    "\n",
    "Se han dividido los datos en conjuntos de entrenamiento y prueba para entrenar el modelo en un conjunto y evaluar su rendimiento en otro conjunto independiente.\n",
    "\n",
    "Se han evaluado el modelo utilizando métricas comunes como la precisión, la recuperación (recall) y la puntuación F1-score, así como la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8532575291948371\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.92      0.91      4988\n",
      "        >50K       0.71      0.63      0.67      1520\n",
      "\n",
      "    accuracy                           0.85      6508\n",
      "   macro avg       0.80      0.78      0.79      6508\n",
      "weighted avg       0.85      0.85      0.85      6508\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4597  391]\n",
      " [ 564  956]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos procesado\n",
    "file_path_processed = \"dataset_procesado.csv\"\n",
    "df_processed = pd.read_csv(file_path_processed)\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y variable objetivo (y)\n",
    "X = df_processed.drop(\"income\", axis=1)\n",
    "y = df_processed[\"income\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de Random Forest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEJORANDO EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Hiperparámetros: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Inicializar el modelo\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Realizar búsqueda en cuadrícula\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores Hiperparámetros:\", grid_search.best_params_)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una búsqueda en cuadrícula para encontrar los mejores hiperparámetros para el modelo de Random Forest. Los hiperparámetros óptimos son:\n",
    "\n",
    "max_depth: None\n",
    "min_samples_leaf: 2\n",
    "min_samples_split: 5\n",
    "n_estimators: 200\n",
    "Utilizar estos hiperparámetros para entrenar un nuevo modelo y evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del mejor modelo: 0.8660110633066994\n",
      "\n",
      "Classification Report del mejor modelo:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.94      0.91      4988\n",
      "        >50K       0.76      0.63      0.69      1520\n",
      "\n",
      "    accuracy                           0.87      6508\n",
      "   macro avg       0.82      0.78      0.80      6508\n",
      "weighted avg       0.86      0.87      0.86      6508\n",
      "\n",
      "\n",
      "Confusion Matrix del mejor modelo:\n",
      " [[4682  306]\n",
      " [ 566  954]]\n"
     ]
    }
   ],
   "source": [
    "# Crear y entrenar el modelo de Random Forest con los mejores hiperparámetros\n",
    "best_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del nuevo modelo\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Mostrar resultados del nuevo modelo\n",
    "print(f\"Accuracy del mejor modelo: {accuracy_best}\")\n",
    "print(\"\\nClassification Report del mejor modelo:\\n\", classification_rep_best)\n",
    "print(\"\\nConfusion Matrix del mejor modelo:\\n\", conf_matrix_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTE DE HIPERPARAMETROS CON OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Terán\\Documents\\finalProject\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-01-23 20:05:21,868] A new study created in memory with name: no-name-0eda1451-cd73-4bcb-9b91-9b4719c6a874\n",
      "[I 2024-01-23 20:05:28,453] Trial 0 finished with value: 0.8612476951444377 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8612476951444377.\n",
      "[I 2024-01-23 20:05:31,542] Trial 1 finished with value: 0.8606330669944684 and parameters: {'n_estimators': 66, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8612476951444377.\n",
      "[I 2024-01-23 20:05:43,518] Trial 2 finished with value: 0.8633988936693301 and parameters: {'n_estimators': 167, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8633988936693301.\n",
      "[I 2024-01-23 20:05:50,515] Trial 3 finished with value: 0.8610940381069453 and parameters: {'n_estimators': 153, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8633988936693301.\n",
      "[I 2024-01-23 20:05:59,065] Trial 4 finished with value: 0.8637062077443147 and parameters: {'n_estimators': 124, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8637062077443147.\n",
      "[I 2024-01-23 20:06:06,659] Trial 5 finished with value: 0.8614013521819299 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.8637062077443147.\n",
      "[I 2024-01-23 20:06:11,463] Trial 6 finished with value: 0.8610940381069453 and parameters: {'n_estimators': 108, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.8637062077443147.\n",
      "[I 2024-01-23 20:06:20,813] Trial 7 finished with value: 0.8633988936693301 and parameters: {'n_estimators': 143, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8637062077443147.\n",
      "[I 2024-01-23 20:06:31,560] Trial 8 finished with value: 0.8649354640442533 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.8649354640442533.\n",
      "[I 2024-01-23 20:06:34,524] Trial 9 finished with value: 0.8594038106945298 and parameters: {'n_estimators': 68, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.8649354640442533.\n",
      "[I 2024-01-23 20:06:41,853] Trial 10 finished with value: 0.8646281499692686 and parameters: {'n_estimators': 105, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.8649354640442533.\n",
      "[I 2024-01-23 20:06:55,856] Trial 11 finished with value: 0.8650891210817455 and parameters: {'n_estimators': 195, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8650891210817455.\n",
      "[I 2024-01-23 20:07:09,952] Trial 12 finished with value: 0.8641671788567916 and parameters: {'n_estimators': 199, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8650891210817455.\n",
      "[I 2024-01-23 20:07:24,655] Trial 13 finished with value: 0.8658574062692072 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:07:38,768] Trial 14 finished with value: 0.8650891210817455 and parameters: {'n_estimators': 198, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:07:52,278] Trial 15 finished with value: 0.8653964351567301 and parameters: {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:08:05,592] Trial 16 finished with value: 0.8653964351567301 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:08:19,360] Trial 17 finished with value: 0.864320835894284 and parameters: {'n_estimators': 177, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:08:33,931] Trial 18 finished with value: 0.8646281499692686 and parameters: {'n_estimators': 184, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:08:42,470] Trial 19 finished with value: 0.864320835894284 and parameters: {'n_estimators': 93, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:08:56,780] Trial 20 finished with value: 0.8655500921942225 and parameters: {'n_estimators': 185, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:09:10,968] Trial 21 finished with value: 0.8652427781192379 and parameters: {'n_estimators': 183, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:09:24,737] Trial 22 finished with value: 0.8649354640442533 and parameters: {'n_estimators': 166, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:09:39,147] Trial 23 finished with value: 0.8641671788567916 and parameters: {'n_estimators': 183, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:09:51,469] Trial 24 finished with value: 0.8627842655193608 and parameters: {'n_estimators': 157, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:06,128] Trial 25 finished with value: 0.8655500921942225 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:20,276] Trial 26 finished with value: 0.8629379225568531 and parameters: {'n_estimators': 193, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:30,059] Trial 27 finished with value: 0.8647818070067609 and parameters: {'n_estimators': 124, 'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:42,566] Trial 28 finished with value: 0.8641671788567916 and parameters: {'n_estimators': 167, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:52,287] Trial 29 finished with value: 0.860940381069453 and parameters: {'n_estimators': 149, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:10:57,394] Trial 30 finished with value: 0.8544867854947756 and parameters: {'n_estimators': 53, 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.8658574062692072.\n",
      "[I 2024-01-23 20:11:13,131] Trial 31 finished with value: 0.866318377381684 and parameters: {'n_estimators': 187, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.866318377381684.\n",
      "[I 2024-01-23 20:11:28,577] Trial 32 finished with value: 0.8675476336816226 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:11:42,055] Trial 33 finished with value: 0.8669330055316533 and parameters: {'n_estimators': 170, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:11:55,986] Trial 34 finished with value: 0.8672403196066379 and parameters: {'n_estimators': 172, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:03,796] Trial 35 finished with value: 0.8607867240319607 and parameters: {'n_estimators': 171, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:16,060] Trial 36 finished with value: 0.8623232944068838 and parameters: {'n_estimators': 160, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:25,753] Trial 37 finished with value: 0.8653964351567301 and parameters: {'n_estimators': 133, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:32,827] Trial 38 finished with value: 0.8614013521819299 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:45,490] Trial 39 finished with value: 0.864320835894284 and parameters: {'n_estimators': 166, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:12:55,077] Trial 40 finished with value: 0.8627842655193608 and parameters: {'n_estimators': 135, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:13:09,451] Trial 41 finished with value: 0.8661647203441918 and parameters: {'n_estimators': 186, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:13:24,236] Trial 42 finished with value: 0.8655500921942225 and parameters: {'n_estimators': 176, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:13:38,941] Trial 43 finished with value: 0.8660110633066994 and parameters: {'n_estimators': 188, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:13:46,812] Trial 44 finished with value: 0.8623232944068838 and parameters: {'n_estimators': 171, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:14:02,717] Trial 45 finished with value: 0.8649354640442533 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:14:17,770] Trial 46 finished with value: 0.8633988936693301 and parameters: {'n_estimators': 162, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:14:33,023] Trial 47 finished with value: 0.8673939766441303 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:14:47,360] Trial 48 finished with value: 0.8647818070067609 and parameters: {'n_estimators': 194, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:14:53,270] Trial 49 finished with value: 0.8600184388444991 and parameters: {'n_estimators': 117, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:15:06,423] Trial 50 finished with value: 0.8655500921942225 and parameters: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:15:21,932] Trial 51 finished with value: 0.8658574062692072 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:15:35,583] Trial 52 finished with value: 0.8673939766441303 and parameters: {'n_estimators': 173, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.8675476336816226.\n",
      "[I 2024-01-23 20:15:51,929] Trial 53 finished with value: 0.867701290719115 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:16:04,204] Trial 54 finished with value: 0.8666256914566687 and parameters: {'n_estimators': 156, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:16:17,565] Trial 55 finished with value: 0.867701290719115 and parameters: {'n_estimators': 176, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:16:23,607] Trial 56 finished with value: 0.8624769514443762 and parameters: {'n_estimators': 80, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:16:40,117] Trial 57 finished with value: 0.863859864781807 and parameters: {'n_estimators': 176, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:16:51,335] Trial 58 finished with value: 0.866779348494161 and parameters: {'n_estimators': 144, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:17:05,109] Trial 59 finished with value: 0.8640135218192994 and parameters: {'n_estimators': 197, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:17:21,215] Trial 60 finished with value: 0.8640135218192994 and parameters: {'n_estimators': 182, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:17:34,715] Trial 61 finished with value: 0.867701290719115 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:17:48,154] Trial 62 finished with value: 0.8673939766441303 and parameters: {'n_estimators': 173, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:18:02,160] Trial 63 finished with value: 0.8653964351567301 and parameters: {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:18:15,021] Trial 64 finished with value: 0.864320835894284 and parameters: {'n_estimators': 163, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:18:29,128] Trial 65 finished with value: 0.8633988936693301 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:18:41,408] Trial 66 finished with value: 0.8666256914566687 and parameters: {'n_estimators': 155, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:18:55,556] Trial 67 finished with value: 0.8647818070067609 and parameters: {'n_estimators': 177, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:19:08,798] Trial 68 finished with value: 0.8655500921942225 and parameters: {'n_estimators': 173, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:19:21,397] Trial 69 finished with value: 0.8644744929317763 and parameters: {'n_estimators': 166, 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:19:29,407] Trial 70 finished with value: 0.8620159803318992 and parameters: {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 53 with value: 0.867701290719115.\n",
      "[I 2024-01-23 20:19:42,592] Trial 71 finished with value: 0.8680086047940996 and parameters: {'n_estimators': 182, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:19:56,062] Trial 72 finished with value: 0.867701290719115 and parameters: {'n_estimators': 185, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:20:09,444] Trial 73 finished with value: 0.8670866625691457 and parameters: {'n_estimators': 187, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:20:22,811] Trial 74 finished with value: 0.8660110633066994 and parameters: {'n_estimators': 184, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:20:36,044] Trial 75 finished with value: 0.8680086047940996 and parameters: {'n_estimators': 182, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:20:50,285] Trial 76 finished with value: 0.8675476336816226 and parameters: {'n_estimators': 196, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:21:03,300] Trial 77 finished with value: 0.8644744929317763 and parameters: {'n_estimators': 198, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:21:16,208] Trial 78 finished with value: 0.864320835894284 and parameters: {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:21:28,235] Trial 79 finished with value: 0.864320835894284 and parameters: {'n_estimators': 182, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:21:41,634] Trial 80 finished with value: 0.8637062077443147 and parameters: {'n_estimators': 196, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:21:55,606] Trial 81 finished with value: 0.8675476336816226 and parameters: {'n_estimators': 192, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:22:08,994] Trial 82 finished with value: 0.8670866625691457 and parameters: {'n_estimators': 187, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:22:22,826] Trial 83 finished with value: 0.8675476336816226 and parameters: {'n_estimators': 189, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:22:36,187] Trial 84 finished with value: 0.8658574062692072 and parameters: {'n_estimators': 182, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:22:50,554] Trial 85 finished with value: 0.8647818070067609 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:23:03,112] Trial 86 finished with value: 0.8664720344191764 and parameters: {'n_estimators': 168, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:23:10,383] Trial 87 finished with value: 0.8672403196066379 and parameters: {'n_estimators': 97, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:23:18,582] Trial 88 finished with value: 0.8620159803318992 and parameters: {'n_estimators': 195, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:23:34,259] Trial 89 finished with value: 0.8657037492317148 and parameters: {'n_estimators': 191, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:23:46,537] Trial 90 finished with value: 0.8623232944068838 and parameters: {'n_estimators': 185, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:24:00,465] Trial 91 finished with value: 0.8675476336816226 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 71 with value: 0.8680086047940996.\n",
      "[I 2024-01-23 20:24:13,421] Trial 92 finished with value: 0.8681622618315918 and parameters: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:24:26,525] Trial 93 finished with value: 0.8678549477566072 and parameters: {'n_estimators': 178, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:24:39,371] Trial 94 finished with value: 0.8681622618315918 and parameters: {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:24:52,047] Trial 95 finished with value: 0.867701290719115 and parameters: {'n_estimators': 176, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:25:03,703] Trial 96 finished with value: 0.866318377381684 and parameters: {'n_estimators': 160, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:25:15,988] Trial 97 finished with value: 0.8649354640442533 and parameters: {'n_estimators': 169, 'max_depth': None, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:25:28,608] Trial 98 finished with value: 0.8653964351567301 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n",
      "[I 2024-01-23 20:25:41,773] Trial 99 finished with value: 0.8681622618315918 and parameters: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 92 with value: 0.8681622618315918.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Hiperparámetros: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 9, 'min_samples_leaf': 2}\n",
      "Mejor Precisión: 0.8681622618315918\n",
      "Accuracy del mejor modelo: 0.8681622618315918\n",
      "\n",
      "Classification Report del mejor modelo:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.94      0.92      4988\n",
      "        >50K       0.76      0.63      0.69      1520\n",
      "\n",
      "    accuracy                           0.87      6508\n",
      "   macro avg       0.83      0.79      0.80      6508\n",
      "weighted avg       0.86      0.87      0.86      6508\n",
      "\n",
      "\n",
      "Confusion Matrix del mejor modelo:\n",
      " [[4694  294]\n",
      " [ 564  956]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import optuna\n",
    "\n",
    "# Cargar el conjunto de datos procesado\n",
    "file_path_processed = \"dataset_procesado.csv\"\n",
    "df_processed = pd.read_csv(file_path_processed)\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y variable objetivo (y)\n",
    "X = df_processed.drop(\"income\", axis=1)\n",
    "y = df_processed[\"income\"]\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Función de objetivo para la optimización de Optuna\n",
    "def objective(trial):\n",
    "    # Definir espacio de búsqueda para hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "\n",
    "    # Crear y entrenar el modelo de Random Forest con hiperparámetros sugeridos por Optuna\n",
    "    model = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Crear un estudio Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # Puedes ajustar el número de ensayos (trials)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y la precisión asociada\n",
    "print(\"Mejores Hiperparámetros:\", study.best_params)\n",
    "print(\"Mejor Precisión:\", study.best_value)\n",
    "\n",
    "# Obtener el mejor modelo con los hiperparámetros optimizados\n",
    "best_model = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    min_samples_split=study.best_params['min_samples_split'],\n",
    "    min_samples_leaf=study.best_params['min_samples_leaf']\n",
    ")\n",
    "\n",
    "# Entrenar el mejor modelo\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del mejor modelo\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Mostrar resultados del mejor modelo\n",
    "print(f\"Accuracy del mejor modelo: {accuracy_best}\")\n",
    "print(\"\\nClassification Report del mejor modelo:\\n\", classification_rep_best)\n",
    "print(\"\\nConfusion Matrix del mejor modelo:\\n\", conf_matrix_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
